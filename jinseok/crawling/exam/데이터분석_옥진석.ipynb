{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dbaa125694f5ca4",
   "metadata": {},
   "source": [
    "### Question1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3feb0c",
   "metadata": {},
   "source": [
    "### 문제 1\n",
    "\n",
    "다음은 빅데이터 수집방식에 대한 설명이다. 빈 칸에 알맞은 방식을 고르시오.\n",
    "\n",
    "댭 : a, f, c, h\n",
    "\n",
    "- ( 로그 수집 )는 웹서버, DB, 트랜잭션 등의 로그를 수집하는 방식\n",
    "- (  크롤링 )는 SNS, 뉴스, 웹 정보 등 인터넷상에서 제공되는 웹문서의 정보를 수집하는 방식\n",
    "- ( 오픈 API )는 웹을 운영하는 사이트에서 정보/데이터를 제공해주는 데이터를 수집하는 방식\n",
    "- ( 센서 수집 )는 날씨, 토양, 수위 등 IoT센서를 이용하여 발생하는 데이터를 수집하는 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5c3972edab5c6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8688e723651d3edf",
   "metadata": {},
   "source": [
    "### 문제 2\n",
    "\n",
    "#### 크롤링의 개념과 필요성에 대해 서술하시오.\n",
    "\n",
    "답: 웹사이트 내 필요한 데이터(텍스트, 속성, 링크)들을 수집하는 기술입니다.\n",
    "\n",
    "동일한 작업을 사람이 직접하게 되면, 많은 시간이 걸리는데 반해 크롤링 기술을 활용하면 더 빠르게, 더 정확하게, 더 많은 데이터를 확보할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9377fa5eb60f51eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "165e4ce8c7efbd46",
   "metadata": {},
   "source": [
    "### 문제 3\n",
    "\n",
    "#### BeautifulSoup의 개념에 대해 서술하시오.\n",
    "\n",
    "답 : 크롤링을 통해 얻은 데이터는 text 파일과 같은 String 데이터임으로 대량의 데이터를 다루기 어렵습니다.\n",
    "\n",
    "BeautifulSoup은 String과 같은 타입을 가진 파이썬 객체를 html이나 lxml등으로 파싱을 하여 유저가 키를 통해 값에 쉽게 접근을 할 수 있도록 지원해주는 라이브러리입니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e8a797",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb10fc6b2b5db02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a70ffe1356391b77",
   "metadata": {},
   "source": [
    "#### 문제 4\n",
    "\n",
    "- find_element : 필요한 요소 찾는 명령으로, 조건에 맞는 값 중 첫번째 요소를 리턴합니다.\n",
    "- find_elements : 복수개의 요소 찾는 명령으로, 조건에 맞는 모든 요소를 리턴합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a90278849f0f02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd15564d1be271de",
   "metadata": {},
   "source": [
    "#### 문제 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21162f48f26e538",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T07:41:03.662023Z",
     "start_time": "2025-04-16T07:41:03.395851Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나를 수집해봐!\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "html = \"\"\"\n",
    "<html>\n",
    "<body>\n",
    " <div>\n",
    " <p>\n",
    "    <a href=“#”><span>나를 수집해봐!</span></a>\n",
    " </p>\n",
    " <p>\n",
    "    <span id=“this_span”>나를 수집해봐!</span>\n",
    " </p>\n",
    " </div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "soup = bs(html, \"lxml\")\n",
    "text = soup.select(\"p > span\")[0].text\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcad885e",
   "metadata": {},
   "source": [
    "### Question2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1d9bb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e05a0e5143f22de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver as wb\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "driver = wb.Chrome()\n",
    "driver.get(\"https://www.naver.com\")\n",
    "\n",
    "search = driver.find_element(By.NAME, \"query\")\n",
    "search.send_keys(\"크롤링\")\n",
    "search.send_keys(Keys.RETURN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d8039bb53da687",
   "metadata": {},
   "source": [
    "#### Question3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3dd988f30269e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  상품      가격   리뷰수\n",
      "0  [쉐이크쉑][매장POS에서만 주문가능/키오스크불가]Shack 베스트 세트(쉑버거2개...  17,100  (52)\n",
      "1                 [푸마]여름 유아동 키즈 주니어 상의2종 하의2종 총 4종세트  13,170   (0)\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver as wb\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "driver = wb.Chrome()\n",
    "driver.get(\"https://www.11st.co.kr/browsing/BestSeller.tmall?method=getBestSellerMain\")\n",
    "\n",
    "title_list = []\n",
    "price_list = []\n",
    "review_list = []\n",
    "\n",
    "for i in range(500) :\n",
    "    pro = driver.find_elements(By.CSS_SELECTOR, \".viewtype.catal_ty > .cfix > li > div > a\")\n",
    "    pro[i].click()\n",
    "    time.sleep(2)\n",
    "\n",
    "    title = driver.find_element(By.CSS_SELECTOR, \"h1.title\")\n",
    "    price = driver.find_element(By.CSS_SELECTOR, \"#finalDscPrcArea > dd.price > strong > span.value\")\n",
    "    review = driver.find_element(By.CSS_SELECTOR, \"#tabMenuDetail2 > i\")\n",
    "\n",
    "    title_list.append(title.text)\n",
    "    price_list.append(price.get_attribute(\"textContent\"))\n",
    "    review_list.append(review.text)\n",
    "\n",
    "    time.sleep(2)\n",
    "    driver.back()\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    '상품': title_list,\n",
    "    '가격': price_list,\n",
    "    '리뷰수': review_list\n",
    "})\n",
    "\n",
    "top5 = df.head(5)\n",
    "\n",
    "print(top5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0134f586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46960d5d28b2556d",
   "metadata": {},
   "source": [
    "#### Question4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7f8ba91fa2400023",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver as wb\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "driver = wb.Chrome()\n",
    "driver.get(\"https://www.melon.com/chart/index.htm\")\n",
    "\n",
    "ranks = []\n",
    "titles = []\n",
    "artists = []\n",
    "likes = []\n",
    "\n",
    "for i in range(100):\n",
    "    rank = driver.find_elements(By.CSS_SELECTOR, \"td > div > span.rank\")[i].text\n",
    "    title = driver.find_elements(By.CSS_SELECTOR, \"div.ellipsis.rank01\")[i].text\n",
    "    artist = driver.find_elements(By.CSS_SELECTOR, \"div.ellipsis.rank02\")[i].text\n",
    "    like = driver.find_elements(By.CSS_SELECTOR, \"td > div > button > span.cnt\")[i].text\n",
    "    \n",
    "    ranks.append(rank)\n",
    "    titles.append(title)\n",
    "    artists.append(artist)\n",
    "    likes.append(like)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    '순위': ranks,\n",
    "    '곡명': titles,\n",
    "    '가수': artists,\n",
    "    '좋아요': likes\n",
    "})\n",
    "\n",
    "df .to_csv(\"멜론차트.csv\", encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
